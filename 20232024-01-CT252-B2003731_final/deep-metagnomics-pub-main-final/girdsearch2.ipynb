{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c63e4761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/ipykernel_launcher.py:88: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "216 fits failed out of a total of 432.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "216 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n",
      "    return super().fit(x, y, **kwargs)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_file44zub3qp.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1024, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1083, in compute_loss\n",
      "        y, y_pred, sample_weight, regularization_losses=self.losses\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 152, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 284, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n",
      "        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/backend.py\", line 5681, in binary_crossentropy\n",
      "        labels=target, logits=output\n",
      "\n",
      "    ValueError: `logits` and `labels` must have the same shape, received ((None, 105) vs (None, 1)).\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91396825 0.86044882 0.90822113 0.86616311 0.91013682 0.91013684\n",
      " 0.91013682 0.90631636 0.90822113 0.90060208 0.90822113 0.91205253\n",
      " 0.91205253 0.88528734 0.91205253 0.87954022 0.90251778 0.91205253\n",
      " 0.90822111 0.90822113 0.90822113 0.91013682 0.90822113 0.90441157\n",
      " 0.91205253 0.86428024 0.90822111 0.8757088  0.91205253 0.91013684\n",
      " 0.90442254 0.91013684 0.90822113 0.90441157 0.90822113 0.90442256\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.91396825 0.86619596 0.91013682 0.87957309 0.91013682 0.90822113\n",
      " 0.90822113 0.90822113 0.91012589 0.91205253 0.90822113 0.90061303\n",
      " 0.90822111 0.88717022 0.91205253 0.87955117 0.91013684 0.90822113\n",
      " 0.90823205 0.91013682 0.90822113 0.90632731 0.90822113 0.91015871\n",
      " 0.91205253 0.86808978 0.9139573  0.88342639 0.91013682 0.91013684\n",
      " 0.91012587 0.91205253 0.90822113 0.9139573  0.90822113 0.9139573 ]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_cnn': 0.2, 'dropout_fc': 0.4, 'filtersize': 3, 'input_reshape': (144, 1), 'loss_func': 'sparse_categorical_crossentropy', 'lr_decay': 1e-06, 'lr_rate': 0.001, 'num_classes': 105, 'numfilter': 16, 'numlayercnn_per_maxpool': 1, 'optimizers_func': <class 'keras.optimizers.optimizer_experimental.adam.Adam'>, 'padded': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def create_cnn_model(input_reshape, num_classes, optimizers_func, lr_rate, lr_decay, decay_steps, decay_rate, loss_func, numfilter=16, filtersize=3, numlayercnn_per_maxpool=1, dropout_cnn=0.2, dropout_fc=0.5, padded=True):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=numfilter, kernel_size=filtersize, activation='relu', input_shape=input_reshape))\n",
    "    if padded:\n",
    "        model.add(tf.keras.layers.ZeroPadding1D(padding=(filtersize // 2)))\n",
    "    for _ in range(numlayercnn_per_maxpool):\n",
    "        model.add(tf.keras.layers.Conv1D(filters=numfilter, kernel_size=filtersize, activation='relu'))\n",
    "        if padded:\n",
    "            model.add(tf.keras.layers.ZeroPadding1D(padding=(filtersize // 2)))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_cnn))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_fc))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Using lr_rate for learning rate and lr_decay for learning rate decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=lr_rate,\n",
    "        decay_steps=decay_steps,  # Define the number of steps for decay\n",
    "        decay_rate=decay_rate,  # Define the decay rate\n",
    "        staircase=True)  # Optional: whether to decay the learning rate at discrete intervals\n",
    "\n",
    "    optimizer = optimizers_func(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])  # Using loss_func parameter here\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/WT2D_x.csv')\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_transposed = data.transpose()\n",
    "label_column = data_transposed.columns[-1]\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "value_counts = y.value_counts()\n",
    "rare_classes = value_counts[value_counts < 2].index\n",
    "y = y[~y.isin(rare_classes)]\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define your decay_steps and decay_rate based on your dataset and requirements\n",
    "decay_steps = 1000  # Replace with your desired value\n",
    "decay_rate = 0.9  # Replace with your desired value\n",
    "\n",
    "# Reshape X for CNN\n",
    "X = X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Further split the training set for parameter tuning\n",
    "X_train_part, _, y_train_part, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'input_reshape': [(X_train.shape[1], 1)],\n",
    "    'num_classes': [len(np.unique(y))],\n",
    "    'optimizers_func': [tf.keras.optimizers.Adam, tf.keras.optimizers.SGD],  # Pass optimizer classes directly\n",
    "    'lr_rate': [0.001, 0.01, 0.1],\n",
    "    'lr_decay': [1e-6, 1e-5, 1e-4],\n",
    "    'decay_steps': [decay_steps],\n",
    "    'decay_rate': [decay_rate],\n",
    "    'numfilter': [16, 32],\n",
    "    'filtersize': [3, 5],\n",
    "    'numlayercnn_per_maxpool': [1],\n",
    "    'dropout_cnn': [0.2],\n",
    "    'dropout_fc': [0.4],\n",
    "    'padded': [True],\n",
    "    'loss_func': ['binary_crossentropy', 'sparse_categorical_crossentropy'],  # Add both loss functions\n",
    "    # Include other hyperparameters you want to tune\n",
    "}\n",
    "# Create CNN model as a KerasClassifier\n",
    "cnn_model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Perform parameter tuning on the part of the training data\n",
    "grid_search = GridSearchCV(estimator=cnn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "grid_search.fit(X_train_part, y_train_part)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c3b3fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/ipykernel_launcher.py:88: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "216 fits failed out of a total of 432.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "216 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 248, in fit\n",
      "    return super().fit(x, y, **kwargs)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/wrappers/scikit_learn.py\", line 175, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/tmp/__autograph_generated_file44zub3qp.py\", line 15, in tf__train_function\n",
      "    retval_ = ag__.converted_call(ag__.ld(step_function), (ag__.ld(self), ag__.ld(iterator)), None, fscope)\n",
      "ValueError: in user code:\n",
      "\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n",
      "        return step_function(self, iterator)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n",
      "        outputs = model.distribute_strategy.run(run_step, args=(data,))\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n",
      "        outputs = model.train_step(data)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1024, in train_step\n",
      "        loss = self.compute_loss(x, y, y_pred, sample_weight)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/training.py\", line 1083, in compute_loss\n",
      "        y, y_pred, sample_weight, regularization_losses=self.losses\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n",
      "        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 152, in __call__\n",
      "        losses = call_fn(y_true, y_pred)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 284, in call  **\n",
      "        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/losses.py\", line 2176, in binary_crossentropy\n",
      "        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n",
      "    File \"/home/xuandai/.local/lib/python3.7/site-packages/keras/backend.py\", line 5681, in binary_crossentropy\n",
      "        labels=target, logits=output\n",
      "\n",
      "    ValueError: `logits` and `labels` must have the same shape, received ((None, 102) vs (None, 1)).\n",
      "\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93697864 0.89303776 0.93697864 0.90453202 0.93889435 0.92552821\n",
      " 0.93316913 0.92743295 0.92552821 0.93697864 0.92552821 0.93698959\n",
      " 0.93697864 0.8816092  0.93698959 0.90264914 0.93889435 0.92552821\n",
      " 0.93698959 0.9274439  0.92552821 0.93697864 0.92552821 0.93697864\n",
      " 0.93507389 0.90264916 0.93507387 0.90645868 0.93700055 0.9274439\n",
      " 0.93316913 0.92552821 0.92552821 0.93698961 0.92552821 0.93316913\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.93697864 0.90071156 0.93698959 0.90261632 0.93316913 0.92552821\n",
      " 0.92933772 0.92552821 0.92552821 0.93315818 0.92552821 0.93316913\n",
      " 0.93507387 0.88539682 0.93889435 0.90453204 0.93316913 0.92552821\n",
      " 0.93698959 0.92552821 0.92552821 0.93507387 0.92362344 0.93887246\n",
      " 0.93697864 0.89881774 0.93507387 0.90644773 0.93316913 0.92552821\n",
      " 0.92552821 0.92552821 0.92552821 0.9274439  0.92552821 0.93507389]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'decay_rate': 0.9, 'decay_steps': 1000, 'dropout_cnn': 0.2, 'dropout_fc': 0.4, 'filtersize': 3, 'input_reshape': (231, 1), 'loss_func': 'sparse_categorical_crossentropy', 'lr_decay': 1e-06, 'lr_rate': 0.01, 'num_classes': 102, 'numfilter': 16, 'numlayercnn_per_maxpool': 1, 'optimizers_func': <class 'keras.optimizers.optimizer_experimental.adam.Adam'>, 'padded': True}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def create_cnn_model(input_reshape, num_classes, optimizers_func, lr_rate, lr_decay, decay_steps, decay_rate, loss_func, numfilter=16, filtersize=3, numlayercnn_per_maxpool=1, dropout_cnn=0.2, dropout_fc=0.5, padded=True):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv1D(filters=numfilter, kernel_size=filtersize, activation='relu', input_shape=input_reshape))\n",
    "    if padded:\n",
    "        model.add(tf.keras.layers.ZeroPadding1D(padding=(filtersize // 2)))\n",
    "    for _ in range(numlayercnn_per_maxpool):\n",
    "        model.add(tf.keras.layers.Conv1D(filters=numfilter, kernel_size=filtersize, activation='relu'))\n",
    "        if padded:\n",
    "            model.add(tf.keras.layers.ZeroPadding1D(padding=(filtersize // 2)))\n",
    "    model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_cnn))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(dropout_fc))\n",
    "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Using lr_rate for learning rate and lr_decay for learning rate decay\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate=lr_rate,\n",
    "        decay_steps=decay_steps,  # Define the number of steps for decay\n",
    "        decay_rate=decay_rate,  # Define the decay rate\n",
    "        staircase=True)  # Optional: whether to decay the learning rate at discrete intervals\n",
    "\n",
    "    optimizer = optimizers_func(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer, loss=loss_func, metrics=['accuracy'])  # Using loss_func parameter here\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/Quin_gut_liver_cirrhosis_x.csv')\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "data_transposed = data.transpose()\n",
    "label_column = data_transposed.columns[-1]\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "value_counts = y.value_counts()\n",
    "rare_classes = value_counts[value_counts < 2].index\n",
    "y = y[~y.isin(rare_classes)]\n",
    "X = X.loc[y.index]\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Define your decay_steps and decay_rate based on your dataset and requirements\n",
    "decay_steps = 1000  # Replace with your desired value\n",
    "decay_rate = 0.9  # Replace with your desired value\n",
    "\n",
    "# Reshape X for CNN\n",
    "X = X.values.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Further split the training set for parameter tuning\n",
    "X_train_part, _, y_train_part, _ = train_test_split(X_train, y_train, test_size=0.8, random_state=42)\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'input_reshape': [(X_train.shape[1], 1)],\n",
    "    'num_classes': [len(np.unique(y))],\n",
    "    'optimizers_func': [tf.keras.optimizers.Adam, tf.keras.optimizers.SGD],  # Pass optimizer classes directly\n",
    "    'lr_rate': [0.001, 0.01, 0.1],\n",
    "    'lr_decay': [1e-6, 1e-5, 1e-4],\n",
    "    'decay_steps': [decay_steps],\n",
    "    'decay_rate': [decay_rate],\n",
    "    'numfilter': [16, 32],\n",
    "    'filtersize': [3, 5],\n",
    "    'numlayercnn_per_maxpool': [1],\n",
    "    'dropout_cnn': [0.2],\n",
    "    'dropout_fc': [0.4],\n",
    "    'padded': [True],\n",
    "    'loss_func': ['binary_crossentropy', 'sparse_categorical_crossentropy'],  # Add both loss functions\n",
    "    # Include other hyperparameters you want to tune\n",
    "}\n",
    "# Create CNN model as a KerasClassifier\n",
    "cnn_model = tf.keras.wrappers.scikit_learn.KerasClassifier(build_fn=create_cnn_model, epochs=10, batch_size=32, verbose=0)\n",
    "\n",
    "# Perform parameter tuning on the part of the training data\n",
    "grid_search = GridSearchCV(estimator=cnn_model, param_grid=param_grid, cv=3, verbose=1)\n",
    "grid_search.fit(X_train_part, y_train_part)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03828fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.9712556732223904\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/metahitIBD_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0db431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.9304084720121029\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/Chatelier_gut_obesity_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66ab4e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.9455370650529501\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/Zeller_fecal_colorectal_cancer_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e8af800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.9576399394856279\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/Quin_gut_liver_cirrhosis_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfbdefb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "Test Accuracy: 0.9409984871406959\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/WT2D_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3381d1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Test Accuracy: 0.9273827534039334\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/t2d_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "# Tạo mô hình SVC\n",
    "svc = SVC()\n",
    "\n",
    "# Tìm kiếm siêu tham số tốt nhất\n",
    "grid_search = GridSearchCV(svc, param_grid, cv=5, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "best_model = grid_search.best_estimator_\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9202839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Tuning): {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': None}\n",
      "Test Accuracy (Final Model): 0.972768532526475\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/metahitIBD_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'random_state': [None, 42, 100],  # Đặt giá trị random_state tùy ý\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Các cách chọn số features khi tìm split node\n",
    "\n",
    "}\n",
    "\n",
    "# Tạo mô hình RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Chia dữ liệu thành tập huấn luyện chính và phần dữ liệu nhỏ để tinh chỉnh tham số\n",
    "X_train_main, X_train_tune, y_train_main, y_train_tune = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập grid search trên phần dữ liệu nhỏ để tinh chỉnh tham số\n",
    "grid_search_tune = GridSearchCV(rf, param_grid, cv=5, verbose=1)\n",
    "grid_search_tune.fit(X_train_tune, y_train_tune)\n",
    "\n",
    "# Siêu tham số tốt nhất từ phần dữ liệu nhỏ\n",
    "best_params_tune = grid_search_tune.best_params_\n",
    "print(\"Best Parameters (Tuning):\", best_params_tune)\n",
    "\n",
    "# Sử dụng toàn bộ dữ liệu huấn luyện chính để fit mô hình với siêu tham số tốt nhất từ phần tinh chỉnh\n",
    "best_model_main = RandomForestClassifier(**best_params_tune)\n",
    "best_model_main.fit(X_train_main, y_train_main)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_score_main = best_model_main.score(X_test, y_test)\n",
    "print(\"Test Accuracy (Final Model):\", test_score_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88006777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 972 candidates, totalling 4860 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuandai/.local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters (Tuning): {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100, 'random_state': None}\n",
      "Test Accuracy (Final Model): 0.9515885022692889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('/mnt/d/20232024-01-CT252-B2003731_final/20232024-01-CT252-B2003731_final/deep-metagnomics-pub-main-final/data/Chatelier_gut_obesity_x.csv')\n",
    "\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Transpose the data\n",
    "data_transposed = data.transpose()\n",
    "\n",
    "# Assuming the last column contains labels\n",
    "label_column = data_transposed.columns[-1]\n",
    "\n",
    "# Define features and labels\n",
    "X = data_transposed.drop(columns=[label_column])\n",
    "y = data_transposed[label_column]\n",
    "\n",
    "# Convert labels to strings\n",
    "y = y.astype(str)\n",
    "\n",
    "# Apply LabelEncoder to labels\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập các siêu tham số để thử nghiệm\n",
    "param_grid = {\n",
    "    \n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'random_state': [None, 42, 100],  # Đặt giá trị random_state tùy ý\n",
    "    'max_features': ['auto', 'sqrt', 'log2']  # Các cách chọn số features khi tìm split node\n",
    "\n",
    "}\n",
    "\n",
    "# Tạo mô hình RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Chia dữ liệu thành tập huấn luyện chính và phần dữ liệu nhỏ để tinh chỉnh tham số\n",
    "X_train_main, X_train_tune, y_train_main, y_train_tune = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Thiết lập grid search trên phần dữ liệu nhỏ để tinh chỉnh tham số\n",
    "grid_search_tune = GridSearchCV(rf, param_grid, cv=5, verbose=1)\n",
    "grid_search_tune.fit(X_train_tune, y_train_tune)\n",
    "\n",
    "# Siêu tham số tốt nhất từ phần dữ liệu nhỏ\n",
    "best_params_tune = grid_search_tune.best_params_\n",
    "print(\"Best Parameters (Tuning):\", best_params_tune)\n",
    "\n",
    "# Sử dụng toàn bộ dữ liệu huấn luyện chính để fit mô hình với siêu tham số tốt nhất từ phần tinh chỉnh\n",
    "best_model_main = RandomForestClassifier(**best_params_tune)\n",
    "best_model_main.fit(X_train_main, y_train_main)\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_score_main = best_model_main.score(X_test, y_test)\n",
    "print(\"Test Accuracy (Final Model):\", test_score_main)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84642fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
